import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import os
from skimage.morphology import skeletonize
from sleeve import (
    _shortest_path_length,
    compute_sleeve_length,
    prune_skeleton,
    DEFAULT_PRUNE_THRESHOLD,
)
try:
    import pillow_heif
except ImportError:  # pragma: no cover
    pillow_heif = None
try:
    import rembg
    session = rembg.new_session("u2netp")
except ImportError:  # pragma: no cover
    rembg = None
    session = None

# HEIC対応読み込み
def load_image(path):
    ext = os.path.splitext(path)[-1].lower()
    if ext == ".heic":
        if pillow_heif is None:
            raise ImportError("pillow_heif is required to load HEIC images")
        heif_file = pillow_heif.read_heif(path)
        img = Image.frombytes(heif_file.mode, heif_file.size, heif_file.data, "raw")
        return cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
    else:
        return cv2.imread(path)

# 黒四角マーカー検出
def detect_marker(image, marker_size_cm=5.0):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    cm_per_pixel = None
    best_cnt = None
    max_area = 0

    for cnt in contours:
        area = cv2.contourArea(cnt)
        if area > 500:  # ノイズ除去
            x, y, w, h = cv2.boundingRect(cnt)
            aspect_ratio = w / float(h)
            if 0.9 < aspect_ratio < 1.1 and area > max_area:
                max_area = area
                best_cnt = cnt

    if best_cnt is not None:
        x, y, w, h = cv2.boundingRect(best_cnt)
        cm_per_pixel = marker_size_cm / np.mean([w, h])
        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)
        cv2.putText(image, "Marker", (x, y - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
    return cm_per_pixel

# 背景除去
def remove_background(image, max_size=None):
    """Remove the background from ``image`` using a cached rembg session.

    Parameters
    ----------
    image : ndarray
        BGR image to process.
    max_size : int, optional
        If given, the image is scaled so that its longest side equals
        ``max_size`` pixels before calling :func:`rembg.remove`. The result is
        then resized back to the original resolution so subsequent measurement
        code can operate on the original scale.
    """

    if rembg is None or session is None:
        raise ImportError("rembg is required for background removal")

    orig_h, orig_w = image.shape[:2]

    scale = 1.0
    if max_size is not None:
        longest = max(orig_h, orig_w)
        if longest > max_size:
            scale = max_size / float(longest)
            new_w = int(orig_w * scale)
            new_h = int(orig_h * scale)
            image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)

    result = rembg.remove(image, session=session)
    result = cv2.cvtColor(np.array(result), cv2.COLOR_RGBA2BGR)

    if scale != 1.0:
        result = cv2.resize(result, (orig_w, orig_h), interpolation=cv2.INTER_LINEAR)

    return result


def resize_for_speed(image, cm_per_pixel, max_size=1200):
    """Downscale ``image`` so its longest side is ``max_size`` pixels.

    Parameters
    ----------
    image : numpy.ndarray
        Input BGR image.
    cm_per_pixel : float
        Conversion factor from pixels to centimeters at the current scale.
    max_size : int, optional
        Target size for the longest side. Images smaller than this are
        returned unchanged. Defaults to ``1200``.

    Returns
    -------
    tuple
        ``(resized_image, adjusted_cm_per_pixel)`` where the scale factor is
        applied equally to both dimensions and ``cm_per_pixel`` is divided by
        that factor so real-world measurements remain accurate.
    """

    h, w = image.shape[:2]
    long_side = max(h, w)
    if long_side <= max_size:
        return image, cm_per_pixel

    scale = max_size / long_side
    resized = cv2.resize(
        image, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_AREA
    )
    return resized, cm_per_pixel / scale


# 服計測
def measure_clothes(image, cm_per_pixel, prune_threshold=DEFAULT_PRUNE_THRESHOLD):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)
    # ノイズ除去のためのクロージング処理
    kernel = np.ones((5, 5), np.uint8)
    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
    contours, _ = cv2.findContours(
        thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
    )

    if not contours:
        return None, {}

    clothes_contour = max(contours, key=cv2.contourArea)

    # 凸包で輪郭を滑らかにする
    hull = cv2.convexHull(clothes_contour)
    x, y, w, h = cv2.boundingRect(hull)

    # ROIに切り出し後のマスクを作成
    gray = gray[y:y + h, x:x + w]
    mask = np.zeros((h, w), dtype=np.uint8)
    shifted_contour = clothes_contour - [x, y]
    cv2.drawContours(mask, [shifted_contour], -1, 255, thickness=-1)

    # 二値マスクから胴体中央線を推定
    projection = mask.sum(axis=0)
    center_x = int(np.argmax(projection))
    column_pixels = np.where(mask[:, center_x] > 0)[0]
    if column_pixels.size == 0:
        raise ValueError("Center line not found")
    top_y = int(column_pixels.min())
    bottom_y = int(column_pixels.max())

    height = bottom_y - top_y

    # 肩幅（上から10%の位置での幅）
    shoulder_y = top_y + int(height * 0.1)
    shoulder_line = mask[shoulder_y:shoulder_y + 5, :]
    shoulder_points = cv2.findNonZero(shoulder_line)
    if shoulder_points is None:
        raise ValueError("Shoulder line not detected")
    shoulder_xs = shoulder_points[:, 0, 0]
    shoulder_ys = shoulder_points[:, 0, 1]
    left_idx = np.argmin(shoulder_xs)
    right_idx = np.argmax(shoulder_xs)
    left_shoulder = (shoulder_xs[left_idx], shoulder_y + shoulder_ys[left_idx])
    right_shoulder = (shoulder_xs[right_idx], shoulder_y + shoulder_ys[right_idx])
    shoulder_width = right_shoulder[0] - left_shoulder[0]



    # 身幅：胴体の25%〜50%の範囲を探索し、最大幅を採用
    kernel_size = max(3, height // 10)
    vertical_kernel = np.ones((kernel_size, 1), np.uint8)
    torso_mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, vertical_kernel)
    torso_mask = cv2.morphologyEx(torso_mask, cv2.MORPH_CLOSE, vertical_kernel)

    max_width = 0
    center_rel = center_x
    start_y = int(top_y + height * 0.25)
    end_y = int(top_y + height * 0.5)

    for y_pos in range(start_y, end_y):
        row = torso_mask[y_pos]
        xs = np.where(row > 0)[0]
        if xs.size == 0:
            continue
        segments = np.split(xs, np.where(np.diff(xs) > 1)[0] + 1)
        for seg in segments:
            if seg[0] <= center_rel <= seg[-1]:
                width = seg[-1] - seg[0]
                if width > max_width:
                    max_width = width
                break

    if max_width == 0:
        raise ValueError("Chest line not detected")
    chest_width = max_width

    skeleton = skeletonize(mask > 0)
    skeleton = prune_skeleton(skeleton, prune_threshold)
    points = np.column_stack(np.nonzero(skeleton)[::-1])
    left_points = points[points[:, 0] < center_x]
    right_points = points[points[:, 0] >= center_x]

    _, _, sleeve_length = compute_sleeve_length(
        left_points, right_points, left_shoulder, right_shoulder
    )

    body_length = _shortest_path_length(
        skeleton, (center_x, top_y), (center_x, bottom_y)
    )



    measures = {
        "肩幅": shoulder_width * cm_per_pixel,
        "身幅": chest_width * cm_per_pixel,
        "身丈": body_length * cm_per_pixel,
        "袖丈": sleeve_length * cm_per_pixel,
    }
    return hull, measures

def _load_japanese_font(font_path, font_size):
    """Return a Pillow font object suitable for rendering Japanese text.

    The function tries several fallback locations so that typical Linux and
    macOS installations work out of the box:

    1. The ``font_path`` argument, if provided.
    2. The ``JP_FONT_PATH`` environment variable.
    3. Common system fonts such as Noto Sans CJK (Linux) or Hiragino/Kosugi
       (macOS).
    4. Finally, Pillow's default bitmap font.
    """

    candidates = []
    if font_path:
        candidates.append(font_path)
    else:
        env_font = os.getenv("JP_FONT_PATH")
        if env_font:
            candidates.append(env_font)
        candidates.extend([
            "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",  # Linux
            "/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc",       # macOS
            "/Library/Fonts/Kosugi-Regular.ttf",                       # macOS user font
        ])

    for path in candidates:
        if path and os.path.exists(path):
            try:
                return ImageFont.truetype(path, size=font_size), font_size
            except OSError:
                continue

    # Fall back to Pillow's default font which may not support Japanese
    return ImageFont.load_default(), 20

# 画像に寸法描画
def draw_measurements_on_image(image, measurements, font_path=None, font_size=150):
    """Draw measurement labels on an image using a Japanese-capable font.

    The overlay text defaults to a large 150 px font so measurements remain
    clearly visible on high-resolution images. When a custom font cannot be
    loaded and Pillow's built-in fallback is used instead, the size is reduced
    to 20 px to match that font's limited metrics.

    Parameters
    ----------
    image : numpy.ndarray
        BGR image as used by OpenCV.
    measurements : dict
        Dictionary mapping measurement names to values.
    font_path : str, optional
        Path to a TrueType font capable of rendering Japanese. When omitted,
        the function searches in the following order:

        1. The ``JP_FONT_PATH`` environment variable
        2. Common system fonts (Noto Sans CJK on Linux, Hiragino/Kosugi on
           macOS)
        3. Pillow's bundled bitmap font, which may lack Japanese glyphs
    font_size : int, optional
        Base font size to use for rendering measurement labels. Defaults to
        150 px and is also used to derive line spacing.
    """

    # Resolve a Japanese-capable font. When no suitable font can be found,
    # Pillow's default bitmap font is used and the size is reduced for better
    # readability.
    font, font_size = _load_japanese_font(font_path, font_size)

    pil_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(pil_img)


    y_offset = 30
    line_height = font_size + 20
    for key, value in measurements.items():
        text = f"{key}: {value:.1f} cm"
        draw.text((30, y_offset), text, font=font, fill=(0, 255, 0))
        y_offset += line_height


    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)

if __name__ == "__main__":
    # ===== メイン処理 =====
    image_path = "画像.jpg"  # HEICもJPEGもOK
    img = load_image(image_path)

    # マーカー検出（背景除去前）
    cm_per_pixel = detect_marker(img)
    if cm_per_pixel is None:
        print("マーカーが検出できません。終了します。")
        exit()

    # 必要に応じて画像を縮小し、縮尺も調整
    img, cm_per_pixel = resize_for_speed(img, cm_per_pixel)

    # 背景除去
    img_no_bg = remove_background(img)

    # 服計測
    try:
        contour, measurements = measure_clothes(img_no_bg, cm_per_pixel)
    except ValueError as e:
        print(f"計測エラー: {e}")
        exit()
    if contour is None:
        print("服が検出できません。")
        exit()

    # 寸法表示
    for k, v in measurements.items():
        print(f"{k}: {v:.1f} cm")

    font_path = os.getenv("JP_FONT_PATH")
    img_with_text = draw_measurements_on_image(
        img.copy(), measurements, font_path=font_path, font_size=200
    )
    cv2.drawContours(img_with_text, [contour], -1, (255, 0, 0), 2)

    # 保存
    cv2.imwrite("clothes_with_measurements.jpg", img_with_text)
    print("寸法入り画像を保存しました → clothes_with_measurements.jpg")

