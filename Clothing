import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import os
import numbers
from measurements import measure_clothes, NoGarmentDetectedError
from image_utils import load_image
try:
    import rembg
    session = rembg.new_session("u2netp")
except ImportError:  # pragma: no cover
    rembg = None
    session = None

# 黒四角マーカー検出
def detect_marker(
    image,
    marker_size_cm: float = 5.0,
    debug: bool = False,
    camera_matrix=None,
    dist_coeffs=None,
):
    """Detect a dark square marker and return its pixel-to-cm scale.

    The previous implementation relied on simple HSV thresholding with a fixed
    value.  This was brittle in real photographs where lighting conditions
    change across the frame or the image contains small noise speckles.  The
    current approach performs the following steps:

    1. Convert to grey and apply both Otsu and adaptive thresholding so the
       binary mask adapts to global as well as local illumination.
    2. Use ``cv2.morphologyEx`` with opening and closing operations to remove
       small artefacts from the mask.
    3. Extract contours and evaluate each using ``cv2.minAreaRect`` so rotated
       markers are handled correctly.  Candidates are filtered by aspect ratio
       and area to avoid false positives.

    Parameters
    ----------
    image : numpy.ndarray
        Input BGR image containing the marker.
    marker_size_cm : float, default ``5.0``
        Physical size of the marker in centimetres.
    debug : bool, default ``False``
        If ``True`` the function also returns an image with visualisation of
        the detection result.
    camera_matrix, dist_coeffs : ndarray, optional
        Camera calibration parameters.  When both are supplied the input image
        is undistorted via :func:`cv2.undistort` before marker detection.

    Returns
    -------
    float or tuple
        When ``debug`` is ``False`` only the ``cm_per_pixel`` scale is
        returned.  If ``debug`` is ``True`` a tuple of ``(cm_per_pixel,
        debug_image)`` is returned where ``debug_image`` contains drawings that
        indicate whether the marker was found.
    """

    if camera_matrix is not None and dist_coeffs is not None:
        image = cv2.undistort(image, camera_matrix, dist_coeffs)

    # --- Step 1: robust binarisation ------------------------------------
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (5, 5), 0)

    # Global Otsu thresholding combined with adaptive thresholding for local
    # variations.  The union of both masks works well for diverse lighting.
    _, otsu = cv2.threshold(
        blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU
    )
    adaptive = cv2.adaptiveThreshold(
        blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 51, 5
    )
    mask = cv2.bitwise_or(otsu, adaptive)

    # Additional robustness: filter very dark regions in HSV space.  This helps
    # to keep black areas even when the overall illumination is uneven.  The
    # resulting mask is combined with the binary mask obtained above.
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    dark = cv2.inRange(hsv, (0, 0, 0), (180, 255, 60))
    mask = cv2.bitwise_or(mask, dark)

    # --- Step 2: morphological noise removal ----------------------------
    # ``np.ones`` would also work here, but ``getStructuringElement`` makes the
    # intent explicit and allows different shapes to be experimented with in
    # the future.  Opening removes isolated speckles.  A light erosion is then
    # applied before closing to ensure that neighbouring dark regions are not
    # merged with the marker.  Finally a median blur smooths remaining noise.
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)
    mask = cv2.erode(mask, kernel, iterations=1)  # keep marker separate
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=1)
    mask = cv2.dilate(mask, kernel, iterations=1)
    mask = cv2.medianBlur(mask, 3)

    # --- Step 3: contour analysis ---------------------------------------
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    cm_per_pixel = None
    best_rect = None
    max_area = 0.0
    image_area = image.shape[0] * image.shape[1]

    for cnt in contours:
        area = cv2.contourArea(cnt)
        if area < 100:  # ignore tiny blobs
            continue

        rect = cv2.minAreaRect(cnt)
        (cx, cy), (w, h), angle = rect
        if w == 0 or h == 0:
            continue

        aspect_ratio = w / h if w > h else h / w
        rect_area = w * h

        # Ignore very large candidates that likely correspond to garment parts
        # (e.g. short sleeves) rather than the small calibration marker.  The
        # marker is expected to be only a tiny fraction of the image so we
        # discard anything covering more than roughly a quarter of the frame.
        if rect_area > image_area * 0.25:
            continue

        if 0.8 < aspect_ratio < 1.25:
            box = cv2.boxPoints(rect)
            box = np.intp(box)

            rect_mask = np.zeros_like(gray)
            cv2.drawContours(rect_mask, [box], 0, 255, -1)
            inner_mean = cv2.mean(gray, mask=rect_mask)[0]

            dilated = cv2.dilate(
                rect_mask, cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))
            )
            ring_mask = cv2.subtract(dilated, rect_mask)
            ring_pixels = cv2.countNonZero(ring_mask)
            outer_mean = (
                cv2.mean(gray, mask=ring_mask)[0] if ring_pixels > 0 else 255
            )

            # Compare contrast relative to the surrounding area instead of using
            # a fixed absolute threshold.  This makes detection work even on
            # darker backgrounds where ``outer_mean`` may be small.
            contrast = (outer_mean - inner_mean) / max(outer_mean, 1)
            if contrast >= 0.25 and rect_area > max_area:
                max_area = rect_area
                best_rect = rect

    if best_rect is not None:
        (cx, cy), _, _ = best_rect
        # ``cv2.minAreaRect`` provides the centre and dimensions of the best
        # fitting rectangle.  Instead of trusting the width/height values
        # directly, derive the side lengths from the corner points.  This offers
        # slightly better numerical stability when the marker is skewed or
        # rotated.
        box = cv2.boxPoints(best_rect)

        # Calculate the average side length of the rectangle from the corner
        # points.  ``minAreaRect`` may yield width/height values that are less
        # stable under heavy rotation or perspective distortion, whereas the
        # Euclidean distance between successive box points remains reliable.
        side_lengths = [
            np.linalg.norm(box[i] - box[(i + 1) % 4]) for i in range(4)
        ]
        side_length = float(np.mean(side_lengths))

        box_int = np.intp(box)

        rect_mask = np.zeros_like(gray)
        cv2.drawContours(rect_mask, [box_int], 0, 255, -1)
        inner_mean = cv2.mean(gray, mask=rect_mask)[0]
        dilated = cv2.dilate(
            rect_mask, cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))
        )
        ring_mask = cv2.subtract(dilated, rect_mask)
        ring_pixels = cv2.countNonZero(ring_mask)
        outer_mean = (
            cv2.mean(gray, mask=ring_mask)[0] if ring_pixels > 0 else 255
        )

        contrast = (outer_mean - inner_mean) / max(outer_mean, 1)
        if contrast >= 0.25:
            if side_length > 0:
                cm_per_pixel = marker_size_cm / side_length

            if debug:
                cv2.drawContours(image, [box_int], 0, (0, 0, 255), 2)
                cv2.putText(
                    image,
                    "Marker",
                    (int(cx), int(cy)),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.6,
                    (0, 0, 255),
                    2,
                )

    if debug and cm_per_pixel is None:
        # Provide visual feedback that detection failed so callers can
        # understand what happened.
        cv2.putText(
            image,
            "No marker",
            (10, 30),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.8,
            (0, 0, 255),
            2,
        )

    return (cm_per_pixel, image) if debug else cm_per_pixel

# GrabCut による輪郭スナップ
def snap_mask_to_edges(bgr, coarse_mask, band_px=8, iters=4):
    """
    coarse_mask（0/255）を出発点に、周囲 band_px の帯域だけを未知にして
    GrabCut を再実行。輪郭を実エッジへ“スナップ”させる。
    戻り値：0/255 の精密マスク
    """
    m = (coarse_mask > 0).astype(np.uint8) * 255
    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2 * band_px + 1, 2 * band_px + 1))
    sure_fg = cv2.erode(m, k, iterations=1)
    sure_bg = cv2.dilate(m, k, iterations=1)
    sure_bg = cv2.bitwise_not(sure_bg)

    gc_mask = np.full(m.shape, cv2.GC_PR_BGD, np.uint8)
    gc_mask[sure_bg > 0] = cv2.GC_BGD
    gc_mask[sure_fg > 0] = cv2.GC_FGD

    bgdModel = np.zeros((1, 65), np.float64)
    fgdModel = np.zeros((1, 65), np.float64)
    cv2.grabCut(bgr, gc_mask, None, bgdModel, fgdModel, iters, cv2.GC_INIT_WITH_MASK)

    out = np.where((gc_mask == cv2.GC_FGD) | (gc_mask == cv2.GC_PR_FGD), 255, 0).astype(np.uint8)
    return out

# 背景除去
def remove_background(image, max_size=None):
    """Remove the background from ``image`` using :mod:`rembg` to obtain a
    clean mask and return a BGR image with a fully black background.

    The original implementation relied on ``rembg`` directly returning an
    image with an alpha channel.  Some versions of the library however produce
    slightly fuzzy masks which results in small leftover blobs around the
    garment.  The revised function therefore requests the mask from
    ``rembg`` (``only_mask=True``), performs additional morphological
    filtering and finally composites the original BGR pixels onto a black
    canvas via :func:`cv2.copyTo`.

    Parameters
    ----------
    image : ndarray
        BGR image to process.
    max_size : int, optional
        If given, the image is scaled so that its longest side equals
        ``max_size`` pixels before calling :func:`rembg.remove`. The mask is
        resized back to the original resolution so subsequent measurement code
        can operate on the original scale.
    """

    if rembg is None or session is None:
        raise ImportError("rembg is required for background removal")

    orig_h, orig_w = image.shape[:2]

    scale = 1.0
    image_resized = image
    if max_size is not None:
        longest = max(orig_h, orig_w)
        if longest > max_size:
            scale = max_size / float(longest)
            new_w = int(orig_w * scale)
            new_h = int(orig_h * scale)
            image_resized = cv2.resize(
                image, (new_w, new_h), interpolation=cv2.INTER_AREA
            )

    # ``rembg`` is invoked twice with ``only_mask=True`` as requested.  The
    # first call acts as a warm-up and the second provides the mask used for
    # further processing.
    rembg.remove(image_resized, session=session, only_mask=True)
    mask = rembg.remove(image_resized, session=session, only_mask=True)
    mask = np.array(mask)
    if mask.ndim == 3:
        mask = mask[:, :, 0]

    # Binarise and clean up the mask. Close first to fill holes, then open to
    # remove speckle noise. Finally dilate slightly to compensate shrinkage.
    _, mask = cv2.threshold(mask, 0, 255, cv2.THRESH_BINARY)
    ell3 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, ell3, iterations=1)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, ell3, iterations=1)
    mask = cv2.dilate(mask, ell3, iterations=1)
    mask = snap_mask_to_edges(image_resized, mask)

    if scale != 1.0:
        mask = cv2.resize(mask, (orig_w, orig_h), interpolation=cv2.INTER_LINEAR)
        image_resized = cv2.resize(
            image_resized, (orig_w, orig_h), interpolation=cv2.INTER_LINEAR
        )

    # Composite the garment on a black background using the cleaned mask.
    result = cv2.copyTo(image_resized, mask)

    return result


def resize_for_speed(image, cm_per_pixel, max_size=1200):
    """Downscale ``image`` so its longest side is ``max_size`` pixels.

    Parameters
    ----------
    image : numpy.ndarray
        Input BGR image.
    cm_per_pixel : float or None
        Conversion factor from pixels to centimeters at the current scale. If
        ``None``, the value is propagated unchanged.
    max_size : int, optional
        Target size for the longest side. Images smaller than this are
        returned unchanged. Defaults to ``1200``.

    Returns
    -------
    tuple
        ``(resized_image, adjusted_cm_per_pixel)`` where the scale factor is
        applied equally to both dimensions and ``cm_per_pixel`` is divided by
        that factor so real-world measurements remain accurate. If
        ``cm_per_pixel`` is ``None``, ``None`` is returned unchanged.
    """

    h, w = image.shape[:2]
    long_side = max(h, w)
    if long_side <= max_size:
        return image, cm_per_pixel

    scale = max_size / long_side
    resized = cv2.resize(
        image, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_AREA
    )
    if cm_per_pixel is None:
        return resized, None
    return resized, cm_per_pixel / scale



def _load_japanese_font(font_path, font_size):
    """Return a Pillow font object suitable for rendering Japanese text.

    The function tries several fallback locations so that typical Linux and
    macOS installations work out of the box:

    1. The ``font_path`` argument, if provided.
    2. The ``JP_FONT_PATH`` environment variable.
    3. Common system fonts such as Noto Sans CJK (Linux) or Hiragino/Kosugi
       (macOS).
    4. Finally, Pillow's default bitmap font.
    """

    candidates = []
    if font_path:
        candidates.append(font_path)
    else:
        env_font = os.getenv("JP_FONT_PATH")
        if env_font:
            candidates.append(env_font)
        candidates.extend([
            "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",  # Linux
            "/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc",       # macOS
            "/Library/Fonts/Kosugi-Regular.ttf",                       # macOS user font
        ])

    for path in candidates:
        if path and os.path.exists(path):
            try:
                return ImageFont.truetype(path, size=font_size), font_size
            except OSError:
                continue

    # Fall back to Pillow's default font which may not support Japanese
    return ImageFont.load_default(), 20

def draw_measurements_on_image(image, measurements, font_path=None, font_size=None):
    """Draw measurement labels on an image using a Japanese-capable font.

    When ``font_size`` is omitted the size is derived from the input image so
    text remains legible regardless of resolution. If a custom font cannot be
    loaded and Pillow's built‑in fallback is used instead, the returned size may
    differ from the requested value.

    Parameters
    ----------
    image : numpy.ndarray
        BGR image as used by OpenCV.
    measurements : dict
        Dictionary mapping measurement names to values.
    font_path : str, optional
        Path to a TrueType font capable of rendering Japanese. When omitted,
        the function searches in the following order:

        1. The ``JP_FONT_PATH`` environment variable
        2. Common system fonts (Noto Sans CJK on Linux, Hiragino/Kosugi on
           macOS)
        3. Pillow's bundled bitmap font, which may lack Japanese glyphs
    font_size : int, optional
        Base font size for rendering measurement labels. If ``None``, a size is
        computed from the image dimensions using ``max(20, min(image.shape[:2])
        // 25)``. The final size returned by the font loader is also used to
        determine line spacing.
    """

    if font_size is None:
        font_size = max(20, min(image.shape[:2]) // 25)

    # Resolve a Japanese-capable font. When no suitable font can be found,
    # Pillow's default bitmap font is used and the size is reduced for better
    # readability.
    font, font_size = _load_japanese_font(font_path, font_size)

    pil_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(pil_img)


    y_offset = 30
    line_height = int(font_size * 1.2)
    for key, value in measurements.items():
        if isinstance(value, numbers.Number):
            text = f"{key}: {value:.1f} cm"
        else:
            text = f"{key}: {value}"
        draw.text((30, y_offset), text, font=font, fill=(0, 255, 0))
        y_offset += line_height


    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)

if __name__ == "__main__":
    # ===== メイン処理 =====
    image_path = "画像.jpg"  # HEICもJPEGもOK
    img = load_image(image_path)

    # マーカー検出（背景除去前）
    cm_per_pixel, debug_img = detect_marker(img, debug=True)
    if cm_per_pixel is None:
        print("マーカーが検出できません。終了します。")
        cv2.imwrite("marker_debug.jpg", debug_img)
        print("検出状況を marker_debug.jpg に保存しました")
        exit()
    else:
        cv2.imwrite("marker_debug.jpg", debug_img)

    # 必要に応じて画像を縮小し、縮尺も調整
    img, cm_per_pixel = resize_for_speed(img, cm_per_pixel)

    # 背景除去
    img_no_bg = remove_background(img)

    # 服計測
    try:
        contour, measurements = measure_clothes(img_no_bg, cm_per_pixel)
    except ValueError as e:
        print(f"計測エラー: {e}")
        exit()
    if contour is None:
        print("服が検出できません。")
        exit()

    # 寸法表示
    for k, v in measurements.items():
        if isinstance(v, numbers.Number):
            print(f"{k}: {v:.1f} cm")
        else:
            print(f"{k}: {v}")

    font_path = os.getenv("JP_FONT_PATH")
    img_with_text = draw_measurements_on_image(
        img.copy(), measurements, font_path=font_path
    )
    cv2.drawContours(img_with_text, [contour], -1, (255, 0, 0), 2)

    # 保存 (重複を避けるためにナンバリング)
    base_name, ext = "clothes_with_measurements", ".jpg"
    filename = base_name + ext
    counter = 1
    while os.path.exists(filename):
        filename = f"{base_name}_{counter}{ext}"
        counter += 1

    cv2.imwrite(filename, img_with_text)
    print(f"寸法入り画像を保存しました → {filename}")

